{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from standard_tester import *\n",
    "\n",
    "from runlmc.models.lmc import LMC\n",
    "from runlmc.kern.rbf import RBF\n",
    "from runlmc.kern.matern32 import Matern32\n",
    "from runlmc.kern.std_periodic import StdPeriodic\n",
    "from runlmc.models.optimization import AdaDelta\n",
    "from runlmc.models.gpy_lmc import GPyLMC\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "xss, yss, test_xss, test_yss, cols = foreign_exchange_33k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33072, 2744)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(len, xss)), sum(map(len, test_xss)) # train,test size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from runlmc.models.lmc import LMC, _LOG\n",
    "logging.getLogger().addHandler(logging.StreamHandler())\n",
    "_LOG.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LMC lmc generating inducing grid n = 33072\n",
      "LMC lmc grid (n = 33072, m = 1004) complete, \n",
      "LMC lmc fully initialized\n",
      "Optimization (121 hyperparams) starting with 4 workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting adadelta {'step_rate': 1, 'decay': 0.9, 'momentum': 0.5, 'offset': 0.0001, 'max_it': 100, 'verbosity': 100, 'min_grad_ratio': 0.5, 'roll': 1, 'permitted_drops': 5}\n",
      "iteration        1 grad norm 5.4916e+02\n",
      "iteration        2 grad norm 5.5345e+02\n",
      "iteration        3 grad norm 5.6654e+02\n",
      "iteration        4 grad norm 5.7085e+02\n",
      "iteration        5 grad norm 5.9197e+02\n",
      "iteration        6 grad norm 6.0008e+02\n",
      "iteration        7 grad norm 6.2748e+02\n",
      "iteration        8 grad norm 6.6708e+02\n",
      "iteration        9 grad norm 1.0446e+03\n",
      "iteration       10 grad norm 1.2146e+03\n",
      "iteration       11 grad norm 9.8537e+02\n",
      "iteration       12 grad norm 1.0772e+03\n",
      "iteration       13 grad norm 1.1134e+03\n",
      "iteration       14 grad norm 1.1043e+03\n",
      "iteration       15 grad norm 1.0713e+03\n",
      "iteration       16 grad norm 9.4864e+02\n",
      "iteration       17 grad norm 3.2848e+03\n",
      "iteration       18 grad norm 7.0379e+03\n",
      "iteration       19 grad norm 3.5419e+03\n",
      "iteration       20 grad norm 3.6393e+02\n",
      "iteration       21 grad norm 7.2104e+02\n",
      "iteration       22 grad norm 1.0712e+03\n",
      "iteration       23 grad norm 1.0469e+03\n",
      "iteration       24 grad norm 1.1347e+03\n",
      "finished adadelta optimization\n",
      "            24 iterations\n",
      "    1.1347e+03 final grad norm\n",
      "    1.1347e+03 final MA(1) grad norm\n",
      "    7.0379e+03 max MA(1) grad norm\n",
      "    norm used inf\n",
      "opt time 6708.890478000045\n"
     ]
    }
   ],
   "source": [
    "m = 1000\n",
    "nk = 4\n",
    "ks = [Matern32(name='mat{}'.format(i)) for i in range(nk)]\n",
    "ranks= [1 for _ in range(nk)]\n",
    "lmc = LMC(xss, yss, kernels=ks, ranks=ranks,                                                                                                                \n",
    "          normalize=True, m=m)                                                                                                                       \n",
    "opt = AdaDelta(verbosity=100)                                                                                                                               \n",
    "with contexttimer.Timer() as t:                                                                                                                                \n",
    "    lmc.optimize(optimizer=opt)\n",
    "print('opt time', t.elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/memex/vyf/lmc', lmc.param_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmc.prediction='precompute'\n",
    "with contexttimer.Timer() as t:\n",
    "    pred_yss, pred_vss = lmc.predict(test_xss)  \n",
    "print('pred time', t.elapsed)\n",
    "print('smse', smse(test_yss, pred_yss, yss))                                                                                                              \n",
    "print('nlpd', nlpd(test_yss, pred_yss, pred_vss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxmax = max(xs.max() for xs in (xss + test_xss))\n",
    "all_ixs = np.arange(maxmax)\n",
    "pred_xss = [all_ixs for _ in cols]\n",
    "pred_yss, pred_vss = lmc.predict(pred_xss)\n",
    "for ix in [0, 5, 8]:\n",
    "    pred_xs = pred_xss[ix]\n",
    "    test_xs = test_xss[ix]\n",
    "    pred_ys = pred_yss[ix]\n",
    "    pred_vs = pred_vss[ix]\n",
    "    test_ys = test_yss[ix]\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "\n",
    "    # Prediction for LLGP\n",
    "    order = np.argsort(pred_xs)\n",
    "    plt.plot(pred_xs[order], pred_ys[order], c='black', label='predicted mu')\n",
    "    sd = np.sqrt(pred_vs)\n",
    "    top = pred_ys + 2 * sd\n",
    "    bot = pred_ys - 2 * sd\n",
    "    plt.fill_between(pred_xs[order], bot[order], top[order], facecolor='grey', alpha=0.2, label='pred var')\n",
    "\n",
    "    # Test\n",
    "    marker_size = 5\n",
    "    plt.scatter(test_xs, test_ys, c='blue', edgecolors='none', s=marker_size, zorder=11, label='test')\n",
    "\n",
    "    # Rest of image (training)\n",
    "    rest_xs = xss[ix]\n",
    "    rest_ys = yss[ix]\n",
    "    plt.scatter(rest_xs, rest_ys, c='magenta', edgecolors='none', s=marker_size, zorder=10, label='train')\n",
    "\n",
    "    plt.title('output {} (95%)'.format(cols[ix]))\n",
    "    plt.xlim([0, max(test_xs.max(), xss[ix].max())])\n",
    "    plt.legend(bbox_to_anchor=(.4, -.05), loc=2)\n",
    "    plt.savefig('/tmp/pics/m' + str(m) + '-' + cols[ix])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cache_dir = '/tmp/'\n",
    "inducing_points = [10]#np.arange(10, 150, 10)\n",
    "num_runs = 1 # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_cached_vars = ['runlmc_times', 'runlmc_smses', 'runlmc_nlpds']\n",
    "if all(os.path.isfile(cache_dir + file) for file in file_cached_vars):\n",
    "    runlmc_times, runlmc_smses, runlmc_nlpds = [\n",
    "        list(np.loadtxt(cache_dir + i)) for i in file_cached_vars]\n",
    "else:\n",
    "    runlmc_times, runlmc_smses, runlmc_nlpds = [], [], []\n",
    "    for m in inducing_points:\n",
    "        time, smse, nlpd, _ = runlmc(\n",
    "            num_runs, m,\n",
    "            xss, yss, test_xss, test_yss,\n",
    "            ks, ranks, {'max_it': np.inf, 'verbosity':0})\n",
    "        print('m', m, 'time', time, 'smse', smse, 'nlpd', nlpd)\n",
    "        runlmc_times.append(time)\n",
    "        runlmc_smses.append(smse)\n",
    "        runlmc_nlpds.append(nlpd)\n",
    "    for i in file_cached_vars:\n",
    "        np.savetxt(cache_dir + i, eval(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cogp_file_cached_vars = ['cogp_times', 'cogp_smses', 'cogp_nlpds']\n",
    "if all(os.path.isfile(cache_dir + file) for file in cogp_file_cached_vars):\n",
    "    cogp_times, cogp_smses, cogp_nlpds = [\n",
    "        list(np.loadtxt(cache_dir + i)) for i in cogp_file_cached_vars]\n",
    "else:\n",
    "    cogp_num_runs = 2\n",
    "    cogp_times, cogp_smses, cogp_nlpds = [], [], []\n",
    "    for m in inducing_points:\n",
    "        time, smse, nlpd = cogp_fx2007(cogp_num_runs, m)\n",
    "        print('m', m, 'time', time, 'smse', smse, 'nlpd', nlpd)\n",
    "        cogp_times.append(time)\n",
    "        cogp_smses.append(smse)\n",
    "        cogp_nlpds.append(nlpd)\n",
    "    for i in cogp_file_cached_vars:\n",
    "        np.savetxt(cache_dir + i, eval(i))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# note m means differnet things for LLGP and COGP\n",
    "# -> use a time frontier graph\n",
    "plt.plot(inducing_points, runlmc_times, label='LLGP')\n",
    "plt.plot(inducing_points, cogp_times, label='COGP')\n",
    "plt.legend(bbox_to_anchor=(1, 0.6), loc=2)\n",
    "plt.title(r'run time vs $m$')\n",
    "plt.xlabel(r'$m$')\n",
    "plt.ylabel('sec')\n",
    "plt.show()\n",
    "plt.plot(inducing_points, runlmc_smses, label='LLGP')\n",
    "plt.plot(inducing_points, cogp_smses, label='COGP')\n",
    "plt.legend(bbox_to_anchor=(1, 0.6), loc=2)\n",
    "plt.title(r'standardized mean square error vs $m$')\n",
    "plt.xlabel(r'$m$')\n",
    "plt.ylabel('smse')\n",
    "plt.show()\n",
    "shift = min(min(runlmc_nlpds), min(cogp_nlpds))\n",
    "assert shift < 0\n",
    "shift = int(abs(shift) * 2)\n",
    "plt.semilogy(inducing_points, np.array(runlmc_nlpds) + shift, label='LLGP')\n",
    "plt.semilogy(inducing_points, np.array(cogp_nlpds) + shift, label='COGP')\n",
    "plt.legend(bbox_to_anchor=(1, 0.6), loc=2)\n",
    "plt.title(r'shifted negative log predictive density vs $m$')\n",
    "plt.xlabel(r'$m$')\n",
    "plt.ylabel('nlpd + {}'.format(shift))\n",
    "plt.show()\n",
    "plt.plot(inducing_points, np.array(runlmc_nlpds), label='LLGP')\n",
    "plt.legend(bbox_to_anchor=(1, 0.6), loc=2)\n",
    "plt.title(r'negative log predictive density vs $m$')\n",
    "plt.xlabel(r'$m$')\n",
    "plt.ylabel('nlpd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
