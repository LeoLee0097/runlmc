{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2016, Vladimir Feinberg\n",
    "# Licensed under the BSD 3-clause license (see LICENSE)\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import contexttimer\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "from runlmc.linalg.kronecker import Kronecker\n",
    "from runlmc.linalg.sum_matrix import SumMatrix\n",
    "from runlmc.linalg.toeplitz import Toeplitz\n",
    "from runlmc.linalg.numpy_matrix import NumpyMatrix\n",
    "import runlmc.util.testing_utils as utils\n",
    "\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "def chan(t): # could be parallel...\n",
    "    n = len(t)\n",
    "    inc = np.arange(n)\n",
    "    l = t * (n - inc)\n",
    "    l = l.astype(float)\n",
    "    r = t[::-1][:-1] * inc[1:]\n",
    "    l[1:] += r\n",
    "    return l / n\n",
    "\n",
    "def inv_precond(lus, perm, inv_perm, x):\n",
    "    D = lus[0][0].shape[0]\n",
    "    x = x.astype('complex').reshape(D, -1)\n",
    "    x = fft(x, overwrite_x=True).reshape(-1)\n",
    "    x = x[perm].reshape(-1, D)\n",
    "    x = np.hstack([scipy.linalg.lu_solve(factors, b) for factors, b in zip(lus, x)])\n",
    "    x = x[inv_perm].reshape(D, -1)\n",
    "    return ifft(x, overwrite_x=True).reshape(-1)\n",
    "\n",
    "def stress_sum_solve(my_mat):\n",
    "    b = np.random.rand(my_mat.shape[0])\n",
    "    sz = len(b)\n",
    "    np_mat = my_mat.as_numpy()\n",
    "    linop = my_mat.as_linear_operator()\n",
    "\n",
    "    tol = 1e-6 # min(np.finfo('float64').eps * sz * max(math.log(sz), 1) * 2, 1e-10)\n",
    "    cond = np.linalg.cond(np_mat)\n",
    "    print('    cond {} tol {:g}'.format(cond, tol))\n",
    "    e = 1e-5\n",
    "    \n",
    "    Bs = np.array([x.A.A for x in my_mat.Ks])\n",
    "    Bs = np.concatenate((Bs, [np.identity(len(Bs[0]))])) #?\n",
    "    tops = np.array([x.B.top for x in my_mat.Ks])\n",
    "    z = np.zeros_like(tops[0])\n",
    "    z[0] += e\n",
    "    tops = np.concatenate((tops, [z])) #?\n",
    "    toep_blocks = np.tensordot(Bs, tops, axes=(0, 0))\n",
    "    circ_pre = np.array([[chan(toep_blocks[i, j])\n",
    "        for j in range(toep_blocks.shape[1])] for i in range(toep_blocks.shape[0])])                         \n",
    "    circ_eigs = fft(circ_pre, overwrite_x=True) # applies to last axis\n",
    "    rc = np.rollaxis(circ_eigs, -1, 0)\n",
    "    lus = [scipy.linalg.lu_factor(dd, overwrite_a=True) for dd in rc]\n",
    "    # the rolled axis perm\n",
    "    perm=np.add.outer(np.arange(circ_eigs.shape[2]), np.arange(circ_eigs.shape[0]) * circ_eigs.shape[2]).ravel()\n",
    "    inv_perm = np.zeros(len(perm), dtype=int)\n",
    "    inv_perm[perm] = np.arange(len(perm))\n",
    "    lx = lambda x: inv_precond(lus, perm, inv_perm, x).real\n",
    "    pre = LinearOperator((sz, sz), matvec=lx, rmatvec=lx)\n",
    "\n",
    "    def time_method(f):\n",
    "        with contexttimer.Timer() as solve_time:\n",
    "            solve, name = f()\n",
    "        print('    {} sec {:8.4f} resid {:8.4e}'.format(\n",
    "            name.rjust(20),\n",
    "            solve_time.elapsed,\n",
    "            np.linalg.norm(linop.matvec(solve) - b)))\n",
    "    time_method(lambda: (np.linalg.solve(np_mat, b), 'linear solve'))\n",
    "\n",
    "    def sparse():\n",
    "        out, succ = scipy.sparse.linalg.cg(my_mat, b, tol=tol, maxiter=sz)\n",
    "        return out, '{} sparse CG'.format('' if not succ else '*')\n",
    "    time_method(sparse)\n",
    "    \n",
    "    def sparsep():\n",
    "        out, succ = scipy.sparse.linalg.cg(my_mat, b, tol=tol, M=pre, maxiter=sz)\n",
    "        return out, '{} sparse CG+P'.format('' if not succ else '*')\n",
    "    time_method(sparsep)\n",
    "\n",
    "    def minres():\n",
    "        out, succ = scipy.sparse.linalg.minres(my_mat, b, tol=tol,\n",
    "                                               maxiter=sz)\n",
    "        return out, '{} sparse MINRES'.format('' if not succ else '*')\n",
    "    time_method(minres)\n",
    "    \n",
    "    def minresp():\n",
    "        out, succ = scipy.sparse.linalg.minres(my_mat, b, tol=tol,\n",
    "                                               M=pre,\n",
    "                                               maxiter=sz)\n",
    "        return out, '{} sparse MINRES+P'.format('' if not succ else '*')\n",
    "    time_method(minresp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* = no convergence\n",
      "size q 3 n 1000 d 4 eps 1e-05\n",
      "random (well-cond) \n",
      "    cond 1664.9544339572756 tol 1e-06\n",
      "            linear solve sec   0.7578 resid 1.8225e-05\n",
      "               sparse CG sec   0.5626 resid 2.9578e-05\n",
      "             sparse CG+P sec   0.5447 resid 8.5177e-06\n",
      "           sparse MINRES sec   0.4947 resid 8.6360e-05\n",
      "         sparse MINRES+P sec   0.3953 resid 1.9974e-03\n",
      "linear decrease (poor-cond)\n",
      "    cond 2738462.7709808256 tol 1e-06\n",
      "            linear solve sec   0.7330 resid 3.6883e-05\n",
      "               sparse CG sec  20.0079 resid 2.8188e-05\n",
      "             sparse CG+P sec   0.2167 resid 3.4931e-05\n",
      "           sparse MINRES sec  14.8719 resid 6.9144e-04\n",
      "         sparse MINRES+P sec   0.2026 resid 4.6861e-05\n",
      "exponentially decreasing (realistic)\n",
      "    cond 41.97426199431347 tol 1e-06\n",
      "            linear solve sec   0.8960 resid 4.3154e-05\n",
      "               sparse CG sec   0.4345 resid 3.5697e-05\n",
      "             sparse CG+P sec   0.3156 resid 9.5542e-06\n",
      "           sparse MINRES sec   0.3471 resid 1.3448e-04\n",
      "         sparse MINRES+P sec   0.2782 resid 3.5242e-04\n"
     ]
    }
   ],
   "source": [
    "# prog n d q eps\n",
    "sys.argv = ['', '1000', '4', '3', '1e-5']\n",
    "\n",
    "print('* = no convergence')\n",
    "utils.run_main(stress_sum_solve, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 100\n",
      "T^-1s\n",
      "LCG 573 PCG 560 PCG2 563\n",
      "eq 3.05476619573e-07 2.92568267283e-07\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "ctr = 0\n",
    "def i(_):\n",
    "    global ctr\n",
    "    ctr += 1\n",
    "\n",
    "T = None\n",
    "t = None\n",
    "s = None\n",
    "while True:\n",
    "    t = np.random.randint(0, 100, 100)\n",
    "    s = np.random.randint(0, 100, 100)\n",
    "    t[::-1].sort()\n",
    "    #t[0] = np.fabs(t[1:]).sum() + 1\n",
    "    T = scipy.linalg.toeplitz(t)\n",
    "    r = np.linalg.matrix_rank(T)\n",
    "    print('rank', r)\n",
    "    if r == 100:\n",
    "        break\n",
    "\n",
    "C = scipy.linalg.circulant(chan(t))\n",
    "print('T^-1s')\n",
    "b = (scipy.sparse.linalg.cg(T, s, tol=1e-10, maxiter=10000, callback=i)[0])\n",
    "lcg = ctr\n",
    "ctr =0\n",
    "iC = np.linalg.inv(C)\n",
    "lo = LinearOperator(C.shape, matvec=(lambda x: iC.dot(x)), rmatvec=(lambda x: iC.dot(x)))\n",
    "ceig = fft(C[0])\n",
    "def mv2(x):\n",
    "    return ifft(fft(x) / ceig).real\n",
    "lo2 = LinearOperator(C.shape, matvec=mv2, rmatvec=mv2)\n",
    "\n",
    "c=(scipy.sparse.linalg.cg(T, s, tol=1e-10, M=lo, maxiter=10000, callback=i)[0])\n",
    "pcg = ctr\n",
    "ctr =0\n",
    "cc=(scipy.sparse.linalg.cg(T, s, tol=1e-10, M=lo2, maxiter=10000, callback=i)[0])\n",
    "pcg2 = ctr\n",
    "ctr =0\n",
    "print('LCG', lcg, 'PCG', pcg, 'PCG2', pcg2)\n",
    "print('eq', np.linalg.norm(b- c), np.linalg.norm(b-cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 100)\n",
      "LCG 7335 PCG 3817 PCG2 3403\n",
      "eq 2.63652168501e-05 2.04259999591e-05\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "ctr = 0\n",
    "def i(_):\n",
    "    global ctr\n",
    "    ctr += 1\n",
    "\n",
    "t = []\n",
    "sz = 100\n",
    "while len(t) < 2:\n",
    "    tt = np.random.rand(sz)\n",
    "    tt[::-1].sort()\n",
    "    TT = scipy.linalg.toeplitz(tt)\n",
    "    while True:\n",
    "        r = np.linalg.matrix_rank(TT)\n",
    "        if r == sz:\n",
    "            break\n",
    "        tt[0] *= 2\n",
    "        TT = scipy.linalg.toeplitz(tt)\n",
    "\n",
    "    t.append(tt)\n",
    "        \n",
    "s = np.random.randn(len(t) * len(t[0]))\n",
    "Bs = np.array([[[3, 1], [1, 3]], [[2, 1], [1, 2]]])\n",
    "tops = np.array(t)\n",
    "tb = np.tensordot(Bs, tops, axes=(0, 0))\n",
    "\n",
    "full = sum(np.kron(b, scipy.linalg.toeplitz(t)) for b, t in zip(Bs, t))\n",
    "print(tb.shape)\n",
    "circ_pre = np.array([[chan(tb[i, j])\n",
    "    for j in range(tb.shape[1])] for i in range(tb.shape[0])])\n",
    "\n",
    "C = np.bmat([[scipy.linalg.circulant(circ_pre[i, j])\n",
    "    for j in range(tb.shape[1])] for i in range(tb.shape[0])]).A\n",
    "\n",
    "b = (scipy.sparse.linalg.cg(full, s, tol=1e-10, maxiter=10000, callback=i)[0])\n",
    "lcg = ctr\n",
    "ctr =0\n",
    "\n",
    "iC = np.linalg.inv(C)\n",
    "lo = LinearOperator(C.shape, matvec=(lambda x: iC.dot(x)), rmatvec=(lambda x: iC.dot(x)))\n",
    "ceig = fft(circ_pre)\n",
    "rc = np.rollaxis(ceig, -1, 0)\n",
    "lus = [scipy.linalg.lu_factor(dd, overwrite_a=True) for dd in rc]\n",
    "# the rolled axis perm\n",
    "perm=np.add.outer(np.arange(ceig.shape[2]), np.arange(ceig.shape[0]) * ceig.shape[2]).ravel()\n",
    "inv_perm = np.zeros(len(perm), dtype=int)\n",
    "inv_perm[perm] = np.arange(len(perm))\n",
    "\n",
    "def mv2(x):\n",
    "    return inv_precond(lus, perm, inv_perm, x).real\n",
    "lo2 = LinearOperator(C.shape, matvec=mv2, rmatvec=mv2)\n",
    "\n",
    "c=(scipy.sparse.linalg.cg(full, s, tol=1e-10, M=lo, maxiter=10000, callback=i)[0])\n",
    "pcg = ctr\n",
    "ctr =0\n",
    "cc=(scipy.sparse.linalg.cg(full, s, tol=1e-10, M=lo2, maxiter=10000, callback=i)[0])\n",
    "pcg2 = ctr\n",
    "ctr =0\n",
    "print('LCG', lcg, 'PCG', pcg, 'PCG2', pcg2)\n",
    "print('eq', np.linalg.norm(b- c), np.linalg.norm(b-cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2016, Vladimir Feinberg\n",
    "# Licensed under the BSD 3-clause license (see LICENSE)\n",
    "\n",
    "# pylint: skip-file\n",
    "\n",
    "import sys\n",
    "\n",
    "import contexttimer\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.spatial.distance\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "from runlmc.approx.interpolation import multi_interpolant\n",
    "from runlmc.kern.rbf import RBF\n",
    "from runlmc.kern.matern32 import Matern32\n",
    "from runlmc.kern.std_periodic import StdPeriodic\n",
    "from runlmc.models.lmc import LMC\n",
    "from runlmc.derivative.lmc_deriv import ExactLMCDerivative, ApproxLMCDerivative\n",
    "\n",
    "_HELP_STR = \"\"\"\n",
    "Usage: python bench.py n_o d q eps [kern] [seed]\n",
    "\n",
    "n_o > 7 is the number of inputs per output\n",
    "d > 0 is the number of outputs\n",
    "q > 0 is the number of LMC kernel terms\n",
    "eps > 0 is the constant diagonal perturbation mean (a float)\n",
    "kern is the kernel type, default rbf, one of 'rbf' 'periodic' 'matern' 'mix'\n",
    "seed is the random seed, default 1234\n",
    "\n",
    "For all benchmarks, this constructs a variety of LMC kernels,\n",
    "all of which conform to the parameters n_o,d,q,eps specified\n",
    "above. The particular kernel constructed is the sum of q ICM\n",
    "terms:\n",
    "\n",
    "  Aq = aa^T, a ~ Normal(mean=0, cov=I)\n",
    "  kappa ~ vector of InverseGamma(shape=1, scale=1)\n",
    "  Bq = Aq + kappa I\n",
    "  Kq = one of RBF, Matern32, StdPeriodic applied to inputs\n",
    "  entire term: HadamardProduct(KroneckerProduct(Bq, 1), Kq\n",
    "\n",
    "Finally, we add independent noise for each output, sampled\n",
    "from InverseGamma(shape=(1 + eps^-1), scale=1)\n",
    "\n",
    "Choose q = d = 1 and n large to test Toeplitz, mainly\n",
    "Choose q = 1 and n ~ d^2 > 7 to test Kronecker, mainly\n",
    "\n",
    "Inputs/outputs are random and uniform in (0, 1). The interpolation grid\n",
    "used by the SKI approximation is a grid with n_o datapoints.\n",
    "\"\"\"\n",
    "\n",
    "def _main():\n",
    "    \"\"\"Runs the benchmarking program.\"\"\"\n",
    "    min_args = 5\n",
    "    max_args = min_args + 2\n",
    "    if len(sys.argv) not in range(min_args, max_args + 1):\n",
    "        print(_HELP_STR)\n",
    "        sys.exit(1)\n",
    "\n",
    "    n_o = int(sys.argv[1])\n",
    "    d = int(sys.argv[2])\n",
    "    q = int(sys.argv[3])\n",
    "    eps = float(sys.argv[4])\n",
    "    kern = sys.argv[5] if len(sys.argv) > 5 else 'rbf'\n",
    "    seed = int(sys.argv[6]) if len(sys.argv) > 6 else 1234\n",
    "    kerntypes = ['rbf', 'periodic', 'matern', 'mix']\n",
    "\n",
    "    assert n_o > 7\n",
    "    assert d > 0\n",
    "    assert q > 0\n",
    "    assert eps > 0\n",
    "    assert kern in kerntypes\n",
    "    np.random.seed(seed)\n",
    "    n = n_o * d\n",
    "\n",
    "    print('n_o {} d {} q {} eps {} kern {} seed {}'.format(\n",
    "        n_o, d, q, eps, kern, seed))\n",
    "\n",
    "    coreg_vecs = np.random.randn(q, d)\n",
    "    coreg_diags = np.reciprocal(np.random.gamma(shape=1, scale=1, size=(q, d)))\n",
    "    noise = np.reciprocal(np.random.gamma(\n",
    "        shape=(1 + (1 / eps)), scale=1, size=d))\n",
    "    kernels = gen_kernels(q)\n",
    "    descriptions = [\n",
    "        'rbf only - inverse lengthscales in logspace(0, 1, q)',\n",
    "        'periodic only - inverse lengthscale is 1, periods in logspace',\n",
    "        'matern32 only - invers lenngthscales in logspace',\n",
    "        'mixed - all the above, with lengthscales/periods in'\n",
    "        ' logspace(0, 1, max(q // 3, 1)']\n",
    "    kdict = {k_name: (k, desc) for k_name, k, desc in\n",
    "             zip(kerntypes, kernels, descriptions)}\n",
    "\n",
    "    Xs, Ys = np.random.rand(2, d, n_o)\n",
    "\n",
    "    dists, grid_dists, interpolant, interpolant_T = prep(d, n_o, Xs)\n",
    "\n",
    "\n",
    "    print()\n",
    "    k, desc = kdict[kern]\n",
    "    run_kernel_benchmark(\n",
    "        k, desc, coreg_vecs, coreg_diags, noise, Xs, np.hstack(Ys),\n",
    "        dists, grid_dists, interpolant, interpolant_T)\n",
    "\n",
    "def prep(d, n_o, Xs):\n",
    "    # Replicates LMC (runlmc.models.lmc) code minimally.\n",
    "    with contexttimer.Timer() as exact:\n",
    "        dists = scipy.spatial.distance.pdist(Xs.reshape(-1, 1))\n",
    "        dists = scipy.spatial.distance.squareform(dists)\n",
    "    with contexttimer.Timer() as apprx:\n",
    "        grid, m = LMC._autogrid(Xs, lo=None, hi=None, m=None)\n",
    "        grid_dists = grid - grid[0]\n",
    "        interpolant = multi_interpolant(Xs, grid)\n",
    "        interpolantT = interpolant.transpose().tocsr()\n",
    "\n",
    "    print()\n",
    "    print('preparation time (once per optimization)')\n",
    "    print('    {:8.4f} sec exact - pairwise distances'.format(exact.elapsed))\n",
    "    print('    {:8.4f} sec apprx - linear interpolation'.format(apprx.elapsed))\n",
    "    return dists, grid_dists, interpolant, interpolantT\n",
    "\n",
    "def run_kernel_benchmark(\n",
    "        kernels, desc, coreg_vecs, coreg_diags, noise, Xs, y,\n",
    "        dists, grid_dists, interpolant, interpolantT):\n",
    "    print(desc)\n",
    "    lens = [len(X) for X in Xs]\n",
    "\n",
    "    with contexttimer.Timer() as t:\n",
    "        exact = ExactLMCDerivative(\n",
    "            coreg_vecs, coreg_diags, kernels, dists, lens, y, noise)\n",
    "    eigs = np.fabs(np.linalg.eigvalsh(exact.K))\n",
    "    print('    covariance matrix info')\n",
    "    print('        largest  eig        {:8.4e}'.format(eigs.max()))\n",
    "    print('        smallest eig        {:8.4e}'.format(eigs.min()))\n",
    "    print('        l2 condition number {:8.4e}'.format(eigs.max() / eigs.min()))\n",
    "    print('    matrix materialization/inversion time')\n",
    "    print('        {:10.4f} sec exact - cholesky'.format(t.elapsed))\n",
    "\n",
    "    with contexttimer.Timer() as t:\n",
    "        apprx = ApproxLMCDerivative(\n",
    "            coreg_vecs, coreg_diags, kernels, grid_dists,\n",
    "            interpolant, interpolantT, lens, y, noise)\n",
    "    print('        {:10.4f} sec apprx - solve K*alpha=y'.format(t.elapsed))\n",
    "\n",
    "    matrix_diff = np.fabs(apprx.ski.as_numpy() - exact.K).mean()\n",
    "    print('        {:9.4e} |K_exact - K_apprx|_1 / n^2'.format(matrix_diff))\n",
    "    alpha_diff = np.fabs(apprx.deriv.alpha - exact.deriv.alpha).mean()\n",
    "    print('        {:9.4e} |alpha_exact - alpha_apprx|_1 / n'\n",
    "          .format(alpha_diff))\n",
    "\n",
    "    \n",
    "\n",
    "    def check_grads(f, name):\n",
    "        with contexttimer.Timer() as t:\n",
    "            exact_kgrad = f(exact)\n",
    "        ngrad = sum(map(len, exact_kgrad))\n",
    "        print('    {} gradients # {}'.format(name, ngrad))\n",
    "        print('        {:10.4f} sec exact per gradient'\n",
    "              .format(t.elapsed / ngrad))\n",
    "        tot_exact_time = t.elapsed\n",
    "        with contexttimer.Timer() as t:\n",
    "            apprx_kgrad = f(apprx)\n",
    "        assert ngrad == sum(map(len, apprx_kgrad))\n",
    "        print('        {:10.4f} sec apprx per gradient'\n",
    "              .format(t.elapsed / ngrad))\n",
    "        tot_apprx_time = t.elapsed\n",
    "        exact_kgrad = np.hstack(exact_kgrad)\n",
    "        apprx_kgrad = np.hstack(exact_kgrad)\n",
    "        err = exact_kgrad - apprx_kgrad\n",
    "        print('        {:9.4e} avg grad error'.format(np.fabs(err).mean()))\n",
    "        print('        {:9.4e} avg signed error'.format(err.mean()))\n",
    "        return err, tot_exact_time, tot_apprx_time\n",
    "\n",
    "    gradient_type = [\n",
    "        (lambda x: x.kernel_gradients(), 'kernel'),\n",
    "        (lambda x: x.coreg_vec_gradients(), 'coregionalization Aq'),\n",
    "        (lambda x: x.coreg_diag_gradients(), 'coregionalization kappa'),\n",
    "        (lambda x: [x.noise_gradient()], 'noise')]\n",
    "\n",
    "    errs = np.array([])\n",
    "    tot_exact_time = 0\n",
    "    tot_apprx_time = 0\n",
    "    for f, name in gradient_type:\n",
    "        err, exact_time, apprx_time = check_grads(f, name)\n",
    "        errs = np.append(errs, err)\n",
    "        tot_exact_time += exact_time\n",
    "        tot_apprx_time += apprx_time\n",
    "\n",
    "    print('    total gradient runtime summary')\n",
    "    print('        {:10.4f} sec exact all gradients'.format(tot_exact_time))\n",
    "    print('        {:10.4f} sec apprx all gradients'.format(tot_apprx_time))\n",
    "    print('        {:9.4e} avg grad error'.format(np.fabs(errs).mean()))\n",
    "    print('        {:9.4e} avg signed error'.format(errs.mean()))\n",
    "\n",
    "\n",
    "\n",
    "def gen_kernels(q):\n",
    "    kern_funcs = [RBF, lambda period: StdPeriodic(1, period), Matern32]\n",
    "    kernels = [[kfunc(gamma)\n",
    "                for gamma in np.logspace(0, 1, q)]\n",
    "               for kfunc in kern_funcs]\n",
    "    kernels.append([kfunc(gamma)\n",
    "                    for gamma in np.logspace(0, 1, max(q // 3, 1))\n",
    "                    for kfunc in kern_funcs])\n",
    "    return kernels\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    _main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
